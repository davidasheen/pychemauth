{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Overview\" data-toc-modified-id=\"Overview-0.1\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;</span>Overview</a></span></li></ul></li><li><span><a href=\"#Load-the-Data\" data-toc-modified-id=\"Load-the-Data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Load the Data</a></span></li><li><span><a href=\"#Model-the-Data-with-PLS-DA\" data-toc-modified-id=\"Model-the-Data-with-PLS-DA-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Model the Data with PLS-DA</a></span><ul class=\"toc-item\"><li><span><a href=\"#Training-a-Hard-Model\" data-toc-modified-id=\"Training-a-Hard-Model-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Training a Hard Model</a></span></li><li><span><a href=\"#Training-a-Soft-Model\" data-toc-modified-id=\"Training-a-Soft-Model-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Training a Soft Model</a></span></li><li><span><a href=\"#Testing\" data-toc-modified-id=\"Testing-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Testing</a></span></li></ul></li><li><span><a href=\"#Optimizing-the-Classifier\" data-toc-modified-id=\"Optimizing-the-Classifier-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Optimizing the Classifier</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nam/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/nam/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.bagging module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/nam/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/nam/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/nam/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/nam/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "import imblearn\n",
    "import sklearn\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "import chemometrics\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import watermark\n",
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview\n",
    "--------\n",
    "This is a simple example of using variants of PLS-DA to do some analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas    0.25.1\n",
      "imblearn  0.5.0\n",
      "numpy     1.21.4\n",
      "json      2.0.9\n",
      "sklearn   0.22.2.post1\n",
      "watermark 2.0.2\n",
      "12:18:42 \n",
      "\n",
      "CPython 3.7.4\n",
      "IPython 7.8.0\n",
      "\n",
      "compiler   : GCC 7.3.0\n",
      "system     : Linux\n",
      "release    : 4.15.0-166-generic\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 8\n",
      "interpreter: 64bit\n"
     ]
    }
   ],
   "source": [
    "%watermark -t -m -v --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load some data from the tests/ for this example\n",
    "df = pd.read_csv('../tests/data/plsda3_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>Class</th>\n",
       "      <th>Name</th>\n",
       "      <th>Li</th>\n",
       "      <th>B</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>...</th>\n",
       "      <th>Eu</th>\n",
       "      <th>Gd</th>\n",
       "      <th>Dy</th>\n",
       "      <th>Ho</th>\n",
       "      <th>Er</th>\n",
       "      <th>Tm</th>\n",
       "      <th>Yb</th>\n",
       "      <th>Lu</th>\n",
       "      <th>Pb</th>\n",
       "      <th>U</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>JPN1</td>\n",
       "      <td>jpn_001</td>\n",
       "      <td>0.001287</td>\n",
       "      <td>0.435363</td>\n",
       "      <td>2.567587</td>\n",
       "      <td>143.601117</td>\n",
       "      <td>0.009235</td>\n",
       "      <td>818.961080</td>\n",
       "      <td>36.075419</td>\n",
       "      <td>...</td>\n",
       "      <td>1.318100e-04</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>2.953350e-04</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>JPN1</td>\n",
       "      <td>jpn_002</td>\n",
       "      <td>0.001474</td>\n",
       "      <td>0.385210</td>\n",
       "      <td>4.595786</td>\n",
       "      <td>276.591018</td>\n",
       "      <td>0.084693</td>\n",
       "      <td>863.273852</td>\n",
       "      <td>50.704790</td>\n",
       "      <td>...</td>\n",
       "      <td>1.823270e-04</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>3.067320e-06</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.000723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>JPN1</td>\n",
       "      <td>jpn_003</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.289601</td>\n",
       "      <td>5.806715</td>\n",
       "      <td>117.037380</td>\n",
       "      <td>0.119564</td>\n",
       "      <td>851.174760</td>\n",
       "      <td>46.020288</td>\n",
       "      <td>...</td>\n",
       "      <td>7.401510e-07</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>5.446410e-05</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.001359</td>\n",
       "      <td>0.000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>JPN1</td>\n",
       "      <td>jpn_004</td>\n",
       "      <td>0.000882</td>\n",
       "      <td>0.525801</td>\n",
       "      <td>0.554544</td>\n",
       "      <td>335.195531</td>\n",
       "      <td>0.388480</td>\n",
       "      <td>836.126629</td>\n",
       "      <td>45.437616</td>\n",
       "      <td>...</td>\n",
       "      <td>1.283760e-04</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>2.635580e-04</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.000236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>JPN1</td>\n",
       "      <td>jpn_005</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.659031</td>\n",
       "      <td>3.102831</td>\n",
       "      <td>213.051823</td>\n",
       "      <td>0.106865</td>\n",
       "      <td>756.238004</td>\n",
       "      <td>39.155470</td>\n",
       "      <td>...</td>\n",
       "      <td>1.014040e-04</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>4.990830e-05</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.001060</td>\n",
       "      <td>0.000130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>340</td>\n",
       "      <td>1</td>\n",
       "      <td>THA1</td>\n",
       "      <td>tha_372</td>\n",
       "      <td>0.008112</td>\n",
       "      <td>0.515135</td>\n",
       "      <td>3.623354</td>\n",
       "      <td>227.360308</td>\n",
       "      <td>0.075525</td>\n",
       "      <td>830.443160</td>\n",
       "      <td>39.884393</td>\n",
       "      <td>...</td>\n",
       "      <td>1.861820e-04</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>7.063200e-07</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.001554</td>\n",
       "      <td>0.000056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>341</td>\n",
       "      <td>1</td>\n",
       "      <td>THA1</td>\n",
       "      <td>tha_373</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.554359</td>\n",
       "      <td>2.752819</td>\n",
       "      <td>397.151899</td>\n",
       "      <td>0.171857</td>\n",
       "      <td>879.746835</td>\n",
       "      <td>45.727848</td>\n",
       "      <td>...</td>\n",
       "      <td>2.826660e-05</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>1.746930e-04</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>0.000180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>342</td>\n",
       "      <td>1</td>\n",
       "      <td>THA1</td>\n",
       "      <td>tha_374</td>\n",
       "      <td>0.006398</td>\n",
       "      <td>0.729045</td>\n",
       "      <td>3.337994</td>\n",
       "      <td>385.826772</td>\n",
       "      <td>0.268925</td>\n",
       "      <td>938.976378</td>\n",
       "      <td>41.141732</td>\n",
       "      <td>...</td>\n",
       "      <td>4.206440e-06</td>\n",
       "      <td>0.000730</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>2.974180e-04</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.003334</td>\n",
       "      <td>0.000208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>343</td>\n",
       "      <td>1</td>\n",
       "      <td>THA1</td>\n",
       "      <td>tha_375</td>\n",
       "      <td>0.009893</td>\n",
       "      <td>0.457777</td>\n",
       "      <td>3.021736</td>\n",
       "      <td>364.285714</td>\n",
       "      <td>0.144162</td>\n",
       "      <td>978.571429</td>\n",
       "      <td>49.285714</td>\n",
       "      <td>...</td>\n",
       "      <td>1.831960e-04</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>2.903890e-04</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000721</td>\n",
       "      <td>0.000079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>344</td>\n",
       "      <td>1</td>\n",
       "      <td>THA1</td>\n",
       "      <td>tha_376</td>\n",
       "      <td>0.006411</td>\n",
       "      <td>0.575608</td>\n",
       "      <td>1.506174</td>\n",
       "      <td>439.939940</td>\n",
       "      <td>0.227648</td>\n",
       "      <td>1139.639640</td>\n",
       "      <td>49.849850</td>\n",
       "      <td>...</td>\n",
       "      <td>9.359490e-05</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>1.980240e-04</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.001252</td>\n",
       "      <td>0.000179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>345 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Group Class     Name        Li         B        Na          Mg        Al  \\\n",
       "0        1  JPN1  jpn_001  0.001287  0.435363  2.567587  143.601117  0.009235   \n",
       "1        1  JPN1  jpn_002  0.001474  0.385210  4.595786  276.591018  0.084693   \n",
       "2        1  JPN1  jpn_003  0.000748  0.289601  5.806715  117.037380  0.119564   \n",
       "3        1  JPN1  jpn_004  0.000882  0.525801  0.554544  335.195531  0.388480   \n",
       "4        1  JPN1  jpn_005  0.001387  0.659031  3.102831  213.051823  0.106865   \n",
       "..     ...   ...      ...       ...       ...       ...         ...       ...   \n",
       "340      1  THA1  tha_372  0.008112  0.515135  3.623354  227.360308  0.075525   \n",
       "341      1  THA1  tha_373  0.000198  0.554359  2.752819  397.151899  0.171857   \n",
       "342      1  THA1  tha_374  0.006398  0.729045  3.337994  385.826772  0.268925   \n",
       "343      1  THA1  tha_375  0.009893  0.457777  3.021736  364.285714  0.144162   \n",
       "344      1  THA1  tha_376  0.006411  0.575608  1.506174  439.939940  0.227648   \n",
       "\n",
       "               K         Ca  ...            Eu        Gd        Dy        Ho  \\\n",
       "0     818.961080  36.075419  ...  1.318100e-04  0.000629  0.000041  0.000108   \n",
       "1     863.273852  50.704790  ...  1.823270e-04  0.000592  0.000386  0.000051   \n",
       "2     851.174760  46.020288  ...  7.401510e-07  0.000717  0.000353  0.000192   \n",
       "3     836.126629  45.437616  ...  1.283760e-04  0.000481  0.000124  0.000041   \n",
       "4     756.238004  39.155470  ...  1.014040e-04  0.000464  0.000608  0.000031   \n",
       "..           ...        ...  ...           ...       ...       ...       ...   \n",
       "340   830.443160  39.884393  ...  1.861820e-04  0.000506  0.000387  0.000062   \n",
       "341   879.746835  45.727848  ...  2.826660e-05  0.000265  0.000556  0.000160   \n",
       "342   938.976378  41.141732  ...  4.206440e-06  0.000730  0.000662  0.000173   \n",
       "343   978.571429  49.285714  ...  1.831960e-04  0.000115  0.000521  0.000150   \n",
       "344  1139.639640  49.849850  ...  9.359490e-05  0.000240  0.000490  0.000095   \n",
       "\n",
       "           Er        Tm            Yb        Lu        Pb         U  \n",
       "0    0.000385  0.000182  2.953350e-04  0.000059  0.000182  0.000174  \n",
       "1    0.000148  0.000021  3.067320e-06  0.000023  0.000443  0.000723  \n",
       "2    0.000434  0.000194  5.446410e-05  0.000016  0.001359  0.000029  \n",
       "3    0.000012  0.000180  2.635580e-04  0.000029  0.000948  0.000236  \n",
       "4    0.000178  0.000102  4.990830e-05  0.000125  0.001060  0.000130  \n",
       "..        ...       ...           ...       ...       ...       ...  \n",
       "340  0.000193  0.000139  7.063200e-07  0.000063  0.001554  0.000056  \n",
       "341  0.000157  0.000057  1.746930e-04  0.000183  0.000947  0.000180  \n",
       "342  0.000183  0.000141  2.974180e-04  0.000193  0.003334  0.000208  \n",
       "343  0.000148  0.000111  2.903890e-04  0.000099  0.000721  0.000079  \n",
       "344  0.000091  0.000140  1.980240e-04  0.000027  0.001252  0.000179  \n",
       "\n",
       "[345 rows x 44 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can see that samples are rows, columns are different features\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_x = np.array(df.values[:,3:], dtype=float) # Extract features\n",
    "raw_y = np.array(df['Class'].values, dtype=str) # Take the class as the target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model the Data with PLS-DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chemometrics.classifier.plsda import PLSDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Hard Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here the data are elemental levels so we will scale the X data\n",
    "plsda = PLSDA(n_components=5, \n",
    "              alpha=0.05, \n",
    "              gamma=0.01, \n",
    "              not_assigned='UNKNOWN', \n",
    "              style=\"hard\", \n",
    "              scale_x=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plsda.fit(raw_x, raw_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plsda.visualize_2d(styles=['hard'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see what samples are predicted to be using the predict() function.\n",
    "pred = plsda.predict(raw_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plsda.score(raw_x, raw_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The score() function is just tetsing how many are correctly predicted.  You can do this directly and \n",
    "# easily with the \"hard\" version of PLS-DA.\n",
    "np.sum(np.array(pred).ravel() == raw_y) / raw_y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More complete figures of merit can be computed.\n",
    "df, I, CSNS, CSPS, CEFF, TSNS, TSPS, TEFF = plsda.figures_of_merit(pred, raw_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df # Each row is what the sample IS, each column is what the PREDICTION is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I # Total fo each category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CEFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TSNS, TSPS, TEFF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Training a Soft Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Here the data are elemental levels so we will scale the X data\n",
    "plsda = PLSDA(n_components=5, \n",
    "              alpha=0.05, \n",
    "              gamma=0.01, \n",
    "              not_assigned='UNKNOWN', \n",
    "              style=\"soft\", \n",
    "              scale_x=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_ = plsda.fit(raw_x, raw_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# You can visualize both the hard and soft boundaries if you train a soft model.\n",
    "# With a hard model, you only get the hard boundaries by default.\n",
    "_ = plsda.visualize_2d(styles=['hard', 'soft'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# We can see what samples are predicted to be using the predict() function.\n",
    "pred = plsda.predict(raw_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Samples can now be predicted to belong to multiple classes.\n",
    "pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# More complete figures of merit can be computed.\n",
    "df, I, CSNS, CSPS, CEFF, TSNS, TSPS, TEFF = plsda.figures_of_merit(pred, raw_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "First, let's test on other pure samples that weren't in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../tests/data/plsda3_test.csv')\n",
    "raw_x_t = np.array(df.values[:,3:], dtype=float)\n",
    "raw_y_t = np.array(['THA2']*len(raw_x), dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pred = plsda.predict(raw_x_t)\n",
    "df, I, CSNS, CSPS, CEFF, TSNS, TSPS, TEFF = plsda.figures_of_merit(pred, raw_y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df # Most foreign samples were CORRECTLY identified as being unknown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Optimizing the Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Here we took alpha as a meaningful choice of type I error rate, but it could also be adjusted.  Moreover, we arbitrarily selected the number of PCs to use in the PLSDA model.  We can use scikit-learn's pipelines to automatically optimize hyperparameters like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Here I've use an imblearn pipeline, but you can also use scikit-learn's pipeline if you don't want to \n",
    "# do any class balancing.\n",
    "\n",
    "pipeline = imblearn.pipeline.Pipeline(steps=[\n",
    "    # Insert other preprocessing steps here...\n",
    "    # (\"smote\", ScaledSMOTEENN(random_state=1)), # For example, class balancing\n",
    "    (\"plsda\", PLSDA(n_components=5, \n",
    "                    alpha=0.05,\n",
    "                    scale_x=True, \n",
    "                    not_assigned='UNKNOWN',\n",
    "                    style='soft', \n",
    "                   )\n",
    "    )\n",
    "])\n",
    "\n",
    "# Hyperparameters of pipeline steps are given in standard notation: step__parameter_name\n",
    "param_grid = [{\n",
    "    # 'smote__k_enn':[1, 2, 3],\n",
    "    # 'smote__k_smote':[1, 3, 3],\n",
    "    # 'smote__kind_sel_enn':['all', 'mode'],\n",
    "    'plsda__n_components':np.arange(1, 20, 2),\n",
    "    'plsda__alpha': [0.07, 0.05, 0.03, 0.01],\n",
    "    #'plsda__scale_x':[True, False],\n",
    "    #'plsda__style':['hard', 'soft'],\n",
    "}]\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    n_jobs=-1,\n",
    "    cv=sklearn.model_selection.StratifiedKFold(n_splits=3, shuffle=True, random_state=0),\n",
    "    error_score=0,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "_ = gs.fit(raw_x, raw_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# The best parameters found can be accessed like this:\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gs.best_score_ # The best score it recieved was..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# You can see detailed CV results here\n",
    "gs.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# For a 1D optimization you can easily visualize where the best value is:\n",
    "# plt.errorbar(np.arange(1, 20, 2), gs.cv_results_['mean_test_score'], yerr=gs.cv_results_['std_test_score'])\n",
    "# plt.xlabel('n_components')\n",
    "# plt.ylabel('Mean Test Score (TEFF)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# scikit-learn finds the optimum over the range, however, you may wish to simply look at these results\n",
    "# and use a smaller value, perhaps at an \"elbow\", and re-train a new model separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# The refit=True (default) refits the model on the data in the end so you can use it directly.\n",
    "gs.best_estimator_.predict(raw_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# You can visualize the training results\n",
    "gs.best_estimator_.named_steps['plsda'].visualize_2d(styles=['hard', 'soft'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Train \n",
    "gs.best_estimator_.named_steps['plsda'].score(raw_x, raw_y) # The score being used here is TEFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pred = gs.best_estimator_.named_steps['plsda'].predict(raw_x)\n",
    "df, I, CSNS, CSPS, CEFF, TSNS, TSPS, TEFF = plsda.figures_of_merit(pred, raw_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pred[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "CSNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "CSPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "CEFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "TSPS, TSNS, TEFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.any(gs.best_estimator_.named_steps['plsda'].check_outliers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Test\n",
    "gs.best_estimator_.named_steps['plsda'].score(raw_x_t, raw_y_t) # The score being used here is TEFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pred = gs.best_estimator_.named_steps['plsda'].predict(raw_x_t)\n",
    "df, I, CSNS, CSPS, CEFF, TSNS, TSPS, TEFF = plsda.figures_of_merit(pred, raw_y_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pred[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
