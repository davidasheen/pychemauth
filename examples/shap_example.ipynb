{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Overview\" data-toc-modified-id=\"Overview-0.1\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;</span>Overview</a></span></li></ul></li><li><span><a href=\"#Analyze-a-DD-SIMCA-Model\" data-toc-modified-id=\"Analyze-a-DD-SIMCA-Model-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Analyze a DD-SIMCA Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-the-Data\" data-toc-modified-id=\"Load-the-Data-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Load the Data</a></span></li><li><span><a href=\"#A-Simple-Model\" data-toc-modified-id=\"A-Simple-Model-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>A Simple Model</a></span></li><li><span><a href=\"#An-Optimized-Pipeline\" data-toc-modified-id=\"An-Optimized-Pipeline-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>An Optimized Pipeline</a></span></li><li><span><a href=\"#Create-an-Explainer\" data-toc-modified-id=\"Create-an-Explainer-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Create an Explainer</a></span></li><li><span><a href=\"#A-Manual-Improvement\" data-toc-modified-id=\"A-Manual-Improvement-1.5\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>A Manual Improvement</a></span></li></ul></li><li><span><a href=\"#Analyze-an-EllipticManifold-Model\" data-toc-modified-id=\"Analyze-an-EllipticManifold-Model-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Analyze an EllipticManifold Model</a></span></li><li><span><a href=\"#Analyze-a-PLS-DA-Model\" data-toc-modified-id=\"Analyze-a-PLS-DA-Model-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Analyze a PLS-DA Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Examine-Categories\" data-toc-modified-id=\"Examine-Categories-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Examine Categories</a></span></li><li><span><a href=\"#How-are-decisions-made?\" data-toc-modified-id=\"How-are-decisions-made?-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>How are decisions made?</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using_colab = 'google.colab' in str(get_ipython())\n",
    "if using_colab:\n",
    "    !git clone https://github.com/mahynski/chemometrics.git\n",
    "    !cd chemometrics; pip3 install -r requirements.txt\n",
    "else:\n",
    "    import sys\n",
    "    sys.path.append('../../')\n",
    "\n",
    "import chemometrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import watermark\n",
    "%load_ext watermark\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import shap\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn\n",
    "import sklearn\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bokeh\n",
    "from bokeh.plotting import output_notebook\n",
    "from chemometrics.utils import bokeh_color_spectrum\n",
    "from chemometrics.utils import color_spectrum\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview\n",
    "-------------\n",
    "This notebook demonstrates the use of SHAP to explain model predictions.\n",
    "\n",
    "For \"soft\" models / OCC, we need to look at the likelihood a sample is assigned as an inlier or not; when models combine many of these (e.g., PLS-DA) we need to pull those apart to inspect each known class.  Typically, a model may be trained and TEFF optimized.  From this, optimal hyperparameters can be extracted then individual models retrained and examined to explain predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%watermark -t -m -v --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Analyze a DD-SIMCA Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Let's load some data from the tests/ for this example\n",
    "if using_colab:\n",
    "    loc = 'https://raw.githubusercontent.com/mahynski/chemometrics/master/tests/data/simca_train.csv'\n",
    "else:\n",
    "    loc = '../tests/data/simca_train.csv'\n",
    "df = pd.read_csv(loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# You can see that samples are rows, columns are different features\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "raw_x = np.array(df.values[:,3:], dtype=float) # Extract features\n",
    "raw_y = np.array(df['Class'].values, dtype=str) # Take the class as the target\n",
    "\n",
    "X_train = raw_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from chemometrics.classifier.simca import DDSIMCA_Model\n",
    "from chemometrics.preprocessing.scaling import CorrectedScaler\n",
    "from chemometrics.preprocessing.filter import SavGol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## A Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Here the data is spectra so we will not scale the X data\n",
    "model = DDSIMCA_Model(n_components=7, alpha=0.05, gamma=0.01, scale_x=False)\n",
    "_ = model.fit(X_train, raw_y)\n",
    "_ = model.visualize(X_train, raw_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mask1 = model.predict_proba(X_train)[:,0] > 0.5\n",
    "mask2 = model.predict(X_train)\n",
    "np.all(mask1 == mask2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.accuracy(X_train, np.array([True]*len(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.score(X_train, np.array([True]*len(X_train))) # Negative log loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## An Optimized Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import imblearn\n",
    "\n",
    "# Let's use some Pareto scaling just as an illustration, even though this may not be ideal with spectral data\n",
    "pipeline = imblearn.pipeline.Pipeline(steps=[\n",
    "    (\"scaling\", \n",
    "     CorrectedScaler(\n",
    "        with_mean=True, \n",
    "        with_std=True, \n",
    "        pareto=True, \n",
    "        biased=False\n",
    "     )\n",
    "    ),\n",
    "    (\"savgol\",\n",
    "     SavGol(\n",
    "         window_length=11, \n",
    "         deriv=2, \n",
    "         polyorder=3\n",
    "     )\n",
    "    ),\n",
    "    (\"simca\", \n",
    "     DDSIMCA_Model(\n",
    "         n_components=7, \n",
    "         alpha=0.05, \n",
    "         scale_x=False\n",
    "     )\n",
    "    )\n",
    "])\n",
    "\n",
    "# Hyperparameters of pipeline steps are given in standard notation: step__parameter_name\n",
    "param_grid = [{\n",
    "    'scaling__pareto': [True, False],\n",
    "    'scaling__with_std': [True, False],\n",
    "    'savgol__window_length': [5, 13],\n",
    "    'savgol__deriv': [0, 1, 2],\n",
    "    'savgol__polyorder': [3],\n",
    "    'simca__n_components': np.arange(1, 10, 2),\n",
    "}]\n",
    "\n",
    "model = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    n_jobs=-1,\n",
    "    cv=sklearn.model_selection.StratifiedKFold(n_splits=3, shuffle=True, random_state=0),\n",
    "    error_score=0,\n",
    "    refit=True,\n",
    ")\n",
    "\n",
    "_ = model.fit(\n",
    "    X_train, \n",
    "    np.array([True]*len(X_train))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.best_params_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# model.cv_results_ # View full CV results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Look for any ties - in this case, not substantially different\n",
    "np.array(model.cv_results_['params'])[model.cv_results_['rank_test_score'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.predict_proba(X_train)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Create an Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# If you have a small dataset with only a few features you can use the entire training dataset for \n",
    "# the background (data). In problems with more features you probably want to pass only the median \n",
    "# of the training dataset, or weighted k-medians.\n",
    "# See https://shap.readthedocs.io/en/latest/example_notebooks/tabular_examples/model_agnostic/Iris%20classification%20with%20scikit-learn.html\n",
    "# Since we have some spectral data with > 400 features, we can just use a random subsample of 10 as \n",
    "# the background.\n",
    "\n",
    "# See SHAP documentation for a discussion on the utility and impact of using a \"squashing function\" to \n",
    "# go from an unbounded \"margin space\" (raw model output) to a bounded probability space.\n",
    "# https://shap.readthedocs.io/en/latest/example_notebooks/tabular_examples/model_agnostic/Squashing%20Effect.html#Probability-space-explaination\n",
    "explainer = shap.KernelExplainer(\n",
    "    model = model.predict_proba, # Use probability function to \"squash\"\n",
    "    data = shap.sample(X_train, 10, random_state=0), # vs. data = X_train to use full training set\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# If there are many features to explain, this can fail to converge. You can choose to look at just\n",
    "# the top features as shown below.  Feature correlation can also be a concern.  Using a smaller subset\n",
    "# of decorrelated inputs.\n",
    "\n",
    "# Consider BorutaShap, Heirarchical clustering, etc.\n",
    "\n",
    "shap_values = explainer.shap_values(X_train, \n",
    "                                    nsamples='auto', # Can increase for lower variance\n",
    "                                    l1_reg='num_features({})'.format(\n",
    "                                        np.min(\n",
    "                                            [X_train.shape[1], 20] # Only look at (up to) the top 20 features\n",
    "                                        )\n",
    "                                    )\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "explainer.expected_value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.mean(model.predict_proba(X_train)[:,0]) \n",
    "# If the background sampling was bad, the mean model prediction will differ greatly from the \n",
    "# explainer.expected_value. If this is large, consider increasing the number of background samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "shap.force_plot(\n",
    "    base_value=explainer.expected_value[0], # [0] to look at inlier probability\n",
    "    shap_values=shap_values[0], # [0] to look at inlier probability\n",
    "    features=X_train, # Feature values for visualization\n",
    "    feature_names=['Channel {}'.format(i) for i in range(X_train.shape[1])] # Feature names for visualization\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Look at the lowest probability example\n",
    "look_at = np.argmin(model.predict_proba(X_train)[:,0]) \n",
    "\n",
    "shap.force_plot(\n",
    "    base_value=explainer.expected_value[0], # [0] to look at inlier probability\n",
    "    shap_values=shap_values[0][look_at,:], # [0] to look at inlier probability\n",
    "    features=raw_x[look_at,:], # Feature values for visualization\n",
    "    feature_names=['Channel {}'.format(i) for i in range(X_train.shape[1])] # Feature names for visualization\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "shap.decision_plot(\n",
    "    explainer.expected_value[0], \n",
    "    shap_values[0][look_at,:],\n",
    "    feature_names=['Channel {}'.format(i) for i in range(raw_x.shape[1])]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ax = color_spectrum(\n",
    "    y=X_train[look_at,:], \n",
    "    x=np.arange(X_train.shape[1]),\n",
    "    importance_values=shap_values[0][look_at], \n",
    "    figsize=(20,5),\n",
    "    cmap='seismic',\n",
    "    bounds=(-0.05, 0.05),\n",
    "    background=True\n",
    ")\n",
    "ax.set_title('Worst Example')\n",
    "\n",
    "# So the spectrum that is most strongly predicted to be an outlier, even though it is NOT is due mostly to\n",
    "# parts of the spectrum that are at low wavenumbers are likely not relevant. This may not be a good \n",
    "# model. In part, this could be due to the fact that those values are poorly sampled/measured so in practice\n",
    "# you might consider getting rid of that part of the spectrum before fitting. The model have learned something\n",
    "# you didn't want it to!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best = np.argmax(model.predict_proba(X_train)[:,0])\n",
    "ax = color_spectrum(\n",
    "    y=X_train[best,:], \n",
    "    x=np.arange(X_train.shape[1]),\n",
    "    importance_values=shap_values[0][best], \n",
    "    figsize=(20,5),\n",
    "    cmap='seismic',\n",
    "    bounds=(-0.05, 0.05),\n",
    "    background=True\n",
    ")\n",
    "ax.set_title('Best Example')\n",
    "\n",
    "# The features that are signalling this spectrum is part of the training class look like they are from \n",
    "# reasonable parts of the spectrum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(\n",
    "    shap_values=shap_values[0],\n",
    "    features=X_train,\n",
    "    plot_type='bar'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## A Manual Improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Let's just choose to trim off the initial part of the spectrum\n",
    "X_refined = X_train[:, 50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import imblearn\n",
    "\n",
    "pipeline = imblearn.pipeline.Pipeline(steps=[\n",
    "    (\"scaling\", \n",
    "     CorrectedScaler(\n",
    "        with_mean=True, \n",
    "        with_std=True, \n",
    "        pareto=True, \n",
    "        biased=False\n",
    "     )\n",
    "    ),\n",
    "    (\"savgol\",\n",
    "     SavGol(\n",
    "         window_length=11, \n",
    "         deriv=2, \n",
    "         polyorder=3\n",
    "     )\n",
    "    ),\n",
    "    (\"simca\", \n",
    "     DDSIMCA_Model(\n",
    "         n_components=7, \n",
    "         alpha=0.05, \n",
    "         scale_x=False\n",
    "     )\n",
    "    )\n",
    "])\n",
    "\n",
    "# Hyperparameters of pipeline steps are given in standard notation: step__parameter_name\n",
    "param_grid = [{\n",
    "    'scaling__pareto': [True, False],\n",
    "    'scaling__with_std': [True, False],\n",
    "    'savgol__window_length': [5, 13],\n",
    "    'savgol__deriv': [0, 1, 2],\n",
    "    'savgol__polyorder': [3],\n",
    "    'simca__n_components': np.arange(1, 10, 2),\n",
    "}]\n",
    "\n",
    "model = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    n_jobs=-1,\n",
    "    cv=sklearn.model_selection.StratifiedKFold(n_splits=3, shuffle=True, random_state=0),\n",
    "    error_score=0,\n",
    "    refit=True,\n",
    ")\n",
    "\n",
    "_ = model.fit(\n",
    "    X_refined, \n",
    "    np.array([True]*len(X_refined))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Look for any ties - in this case, not substantially different\n",
    "np.array(model.cv_results_['params'])[model.cv_results_['rank_test_score'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "explainer = shap.KernelExplainer(\n",
    "    model = model.predict_proba, # Use probability function to \"squash\"\n",
    "    data = shap.sample(X_refined, 10, random_state=0), \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "explainer.expected_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.mean(model.predict_proba(X_refined)[:,0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "shap_values = explainer.shap_values(X_refined, \n",
    "                                    nsamples='auto', # Can increase for lower variance\n",
    "                                    l1_reg='num_features({})'.format(\n",
    "                                        np.min(\n",
    "                                            [X_refined.shape[1], 20] # Only look at (up to) the top 20 features\n",
    "                                        )\n",
    "                                    )\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "worst = np.argmin(model.predict_proba(X_refined)[:,0])\n",
    "\n",
    "ax = color_spectrum(\n",
    "    x=np.arange(X_refined.shape[1]),\n",
    "    y=X_refined[worst,:], \n",
    "    importance_values=shap_values[0][worst], \n",
    "    figsize=(20,5),\n",
    "    cmap='seismic',\n",
    "    bounds=(-0.05, 0.05),\n",
    "    background=True\n",
    ")\n",
    "ax.set_title('Worst Example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "best = np.argmax(model.predict_proba(X_refined)[:,0])\n",
    "\n",
    "ax = color_spectrum(\n",
    "    x=np.arange(X_refined.shape[1]),\n",
    "    y=X_refined[best,:], \n",
    "    importance_values=shap_values[0][best], \n",
    "    figsize=(20,5),\n",
    "    cmap='seismic',\n",
    "    bounds=(-0.05, 0.05),\n",
    "    background=True\n",
    ")\n",
    "ax.set_title('Best Example')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# You have to decide if this makes sense or not.\n",
    "shap.summary_plot(\n",
    "    shap_values=shap_values[0],\n",
    "    features=X_refined,\n",
    "    plot_type='bar'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# We can color an individual spectrum based on the features important to its own classification.\n",
    "# This is useful to diagnose and individual prediction.\n",
    "chosen = 0\n",
    "bokeh_color_spectrum(x=np.arange(X_refined.shape[1]), \n",
    "                     y=X_refined[chosen, :], \n",
    "                     importance_values=shap_values[0][chosen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Or, we can color by the average SHAP importance.\n",
    "# This is useful for visualizing how the model makes predictions on average.\n",
    "chosen = 0\n",
    "bokeh_color_spectrum(x=np.arange(X_refined.shape[1]), \n",
    "                     y=X_refined[chosen, :], \n",
    "                     importance_values=np.mean(np.abs(shap_values[0]), axis=0) # Mean ABSOLUTE value\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Analyze an EllipticManifold Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import sklearn.manifold\n",
    "from chemometrics.manifold.elliptic import EllipticManifold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mani = sklearn.manifold.Isomap\n",
    "kwargs = {\"n_neighbors\":10, \n",
    "          \"n_components\":2, # Choose 2 for visualization\n",
    "          \"metric\":'minkowski',\n",
    "          \"p\":2, \n",
    "         }\n",
    "model = EllipticManifold(0.05, mani, kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_ = model.fit(X_train, raw_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model.visualize([X_train], [\"Training Set\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "explainer = shap.KernelExplainer(\n",
    "    model = model.predict_proba, # Use probability function to \"squash\"\n",
    "    data = shap.sample(X_train, 10, random_state=0), \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "shap_values = explainer.shap_values(X_train, \n",
    "                                    nsamples='auto', # Can increase for lower variance\n",
    "                                    l1_reg='num_features({})'.format(\n",
    "                                        np.min(\n",
    "                                            [X_train.shape[1], 20] # Only look at (up to) the top 20 features\n",
    "                                        )\n",
    "                                    )\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "explainer.expected_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "np.mean(model.predict_proba(X_train)[:,0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# On AVERAGE, it looks like the most important parts of the spectrum are somewhere around channel ~80\n",
    "shap.summary_plot(\n",
    "    shap_values=shap_values[0],\n",
    "    features=X_train,\n",
    "    plot_type='bar'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Or, we can color by the average SHAP importance.\n",
    "# This is useful for visualizing how the model makes predictions on average.\n",
    "chosen = 0\n",
    "bokeh_color_spectrum(x=np.arange(X_train.shape[1]), \n",
    "                     y=X_train[chosen, :], \n",
    "                     importance_values=np.mean(np.abs(shap_values[0]), axis=0) # Mean ABSOLUTE value\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# This model seems to focus on characterizing the spectra based on a region of high variance.\n",
    "chosen = 0\n",
    "bokeh_color_spectrum(x=np.arange(X_train.shape[1]), \n",
    "                     y=X_train[chosen, :], \n",
    "                     importance_values=np.std(X_train, axis=0)**2 # Variance in the training data\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze a PLS-DA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load some data from the tests/ for this example\n",
    "if using_colab:\n",
    "    loc = 'https://raw.githubusercontent.com/mahynski/chemometrics/master/tests/data/plsda3_train.csv'\n",
    "else:\n",
    "    loc = '../tests/data/plsda3_train.csv'\n",
    "df = pd.read_csv(loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now using SITE data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "element_names = df.columns[3:]\n",
    "raw_x = np.array(df.values[:,3:], dtype=float) # Extract features\n",
    "raw_y = np.array(df['Class'].values, dtype=str) # Take the class as the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chemometrics.classifier.plsda import PLSDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here the data are elemental levels so we will scale the X data\n",
    "plsda = PLSDA(n_components=5, \n",
    "              alpha=0.05, \n",
    "              gamma=0.01, \n",
    "              not_assigned='UNKNOWN', \n",
    "              style=\"soft\", \n",
    "              scale_x=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plsda.fit(raw_x, raw_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plsda.visualize(styles=['hard', 'soft'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plsda.predict(raw_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plsda.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plsda.predict_proba(raw_x)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plsda.predict_proba predicts the probability for EACH individual class (in columns).\n",
    "# Athough these do not sum to unity, we can still analyze each column individually with SHAP!\n",
    "\n",
    "explainer = shap.KernelExplainer(\n",
    "    model = plsda.predict_proba, \n",
    "    data = shap.sample(raw_x, 10, random_state=0), # vs. data = raw_x to use full training set\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer.shap_values(raw_x, \n",
    "                                    nsamples='auto', # Can increase for lower variance\n",
    "                                    l1_reg='num_features({})'.format(\n",
    "                                        np.min(\n",
    "                                            [raw_x.shape[1], 20] # Only look at (up to) the top 20 features\n",
    "                                        )\n",
    "                                    )\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(shap_values) # There is a set of shap values for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.expected_value # Average probability of being an inlier for each class in the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Examine Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "chosen_class = 2 # Which category? 0, 1, or 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sv = shap_values[chosen_class]\n",
    "plsda.categories[chosen_class]\n",
    "\n",
    "shap.summary_plot(\n",
    "    shap_values=sv,\n",
    "    features=raw_x,\n",
    "    feature_names=element_names,\n",
    "    plot_type='bar'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# You can see that the SHAP values add up to the probability a point is an inlier in a class:\n",
    "\n",
    "examine_pt = 12\n",
    "\n",
    "shap_sum = np.sum(shap_values[chosen_class][examine_pt]) + explainer.expected_value[chosen_class]\n",
    "pred_prob = plsda.predict_proba(raw_x)[examine_pt][chosen_class]\n",
    "\n",
    "print(shap_sum, pred_prob, shap_sum-pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(\n",
    "    shap_values=sv,\n",
    "    features=raw_x,\n",
    "    feature_names=element_names,\n",
    "    plot_type='violin'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "shap.force_plot(\n",
    "    base_value=explainer.expected_value[chosen_class],\n",
    "    shap_values=sv, \n",
    "    features=raw_x,\n",
    "    feature_names=element_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Look at the lowest probability example\n",
    "look_at = np.argmin(plsda.predict_proba(raw_x)[:,chosen_class]) \n",
    "\n",
    "shap.force_plot(\n",
    "    base_value=explainer.expected_value[chosen_class], \n",
    "    shap_values=sv[look_at,:], \n",
    "    features=raw_x[look_at,:], \n",
    "    feature_names=element_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "shap.decision_plot(\n",
    "    explainer.expected_value[chosen_class], \n",
    "    sv[look_at,:],\n",
    "    feature_names=element_names.tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Look at the highest probability example\n",
    "look_at = np.argmax(plsda.predict_proba(raw_x)[:,chosen_class]) \n",
    "\n",
    "shap.force_plot(\n",
    "    base_value=explainer.expected_value[chosen_class], \n",
    "    shap_values=sv[look_at,:], \n",
    "    features=raw_x[look_at,:], \n",
    "    feature_names=element_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "shap.decision_plot(\n",
    "    explainer.expected_value[chosen_class], \n",
    "    sv[look_at,:],\n",
    "    feature_names=element_names.tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## How are decisions made?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Let's assess the specificity of the model - we can look at examples of when a sample is predicted to belong\n",
    "# to a class that it does not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "chosen_class = 0\n",
    "sv = shap_values[chosen_class]\n",
    "print('Examining model for : {}'.format(plsda.categories[chosen_class])) # Let's look at samples which belong to this category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "compare_class = (chosen_class+1)%3 # Let's see how the model predicts for other classes\n",
    "print('These samples belong to : {}'.format(plsda.categories[compare_class]))\n",
    "\n",
    "# Look at samples that belong to compare_class\n",
    "mask = raw_y == plsda.categories[compare_class]\n",
    "\n",
    "# These should NOT be predicted to belong to chosen_class\n",
    "wrong = plsda.predict_proba(raw_x[mask])[:,chosen_class] > 0.5\n",
    "\n",
    "shap.decision_plot(\n",
    "    explainer.expected_value[chosen_class], \n",
    "    sv[mask,:], \n",
    "    feature_names=element_names.tolist(),\n",
    "    highlight=wrong\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Although none are wrong here, some are around 40% and the threshold for class membership is 50%, so \n",
    "# those might be of interest for further investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "compare_class = (chosen_class+2)%3 # Let's see how the model predicts for other classes\n",
    "print('These samples belong to : {}'.format(plsda.categories[compare_class]))\n",
    "\n",
    "# Look at samples that belong to compare_class\n",
    "mask = raw_y == plsda.categories[compare_class]\n",
    "\n",
    "# These should NOT be predicted to belong to chosen_class\n",
    "wrong = plsda.predict_proba(raw_x[mask])[:,chosen_class] > 0.5\n",
    "\n",
    "shap.decision_plot(\n",
    "    explainer.expected_value[chosen_class], \n",
    "    sv[mask,:], \n",
    "    feature_names=element_names.tolist(),\n",
    "    highlight=wrong\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# These ones that are wrong seem like outliers, whereas most are predicted correctly, confidently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# However, in the latent space, these wrong ones appear to be just \"on the edge\" and could be included\n",
    "# if alpha (type 1 error rate) was adjusted.  That is not the point - we WANT a few of those on the edge\n",
    "# to be excluded to draw the boundary, so this appears to be reasonable.\n",
    "t = plsda.transform(raw_x[mask][~wrong])\n",
    "plt.plot(t[:,0], t[:,1], 'o')\n",
    "\n",
    "t = plsda.transform(raw_x[mask][wrong])\n",
    "plt.plot(t[:,0], t[:,1], 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# First incorrect point\n",
    "shap.force_plot(\n",
    "    base_value=explainer.expected_value[chosen_class], \n",
    "    shap_values=sv[mask][wrong,:][0], \n",
    "    features=raw_x[mask][wrong,:][0], \n",
    "    feature_names=element_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Second incorrect point\n",
    "shap.force_plot(\n",
    "    base_value=explainer.expected_value[chosen_class], \n",
    "    shap_values=sv[mask][wrong,:][1], \n",
    "    features=raw_x[mask][wrong,:][1], \n",
    "    feature_names=element_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "compare_class = chosen_class # Let's see how the model predicts for other classes\n",
    "print('These samples belong to : {}'.format(plsda.categories[compare_class]))\n",
    "\n",
    "# Look at samples that belong to compare_class\n",
    "mask = raw_y == plsda.categories[compare_class]\n",
    "\n",
    "# These SHOULD be predicted to belong to chosen_class\n",
    "wrong = plsda.predict_proba(raw_x[mask])[:,chosen_class] < 0.5\n",
    "\n",
    "shap.decision_plot(\n",
    "    explainer.expected_value[chosen_class], \n",
    "    sv[mask,:], \n",
    "    feature_names=element_names.tolist(),\n",
    "    highlight=wrong\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Although a few are wrong, they are pretty close to the \"pack\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
