{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Overview\" data-toc-modified-id=\"Overview-0.1\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;</span>Overview</a></span></li></ul></li><li><span><a href=\"#Load-some-Data\" data-toc-modified-id=\"Load-some-Data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Load some Data</a></span></li><li><span><a href=\"#Iterative-PCA-(Missing-X-values)\" data-toc-modified-id=\"Iterative-PCA-(Missing-X-values)-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Iterative PCA (Missing X values)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Fixed-n_components\" data-toc-modified-id=\"Fixed-n_components-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Fixed n_components</a></span></li><li><span><a href=\"#Unknown-n_components\" data-toc-modified-id=\"Unknown-n_components-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Unknown n_components</a></span></li></ul></li><li><span><a href=\"#Iterative-PLS-(Missing-X-and-y)\" data-toc-modified-id=\"Iterative-PLS-(Missing-X-and-y)-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Iterative PLS (Missing X and y)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Fixed-n_components\" data-toc-modified-id=\"Fixed-n_components-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Fixed n_components</a></span></li><li><span><a href=\"#Unknown-n_components\" data-toc-modified-id=\"Unknown-n_components-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Unknown n_components</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nam/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/nam/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.bagging module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/nam/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/nam/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/nam/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.utils.testing module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.utils. Anything that cannot be imported from sklearn.utils is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/home/nam/anaconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.classification module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "import imblearn\n",
    "import sklearn\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "import chemometrics\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import watermark\n",
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview\n",
    "--------\n",
    "This are some examples ways to impute missing data. scikit-learn has a [library](https://scikit-learn.org/stable/modules/impute.html#univariate-vs-multivariate-imputation) for simple methods which is also very useful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json      2.0.9\n",
      "watermark 2.0.2\n",
      "imblearn  0.5.0\n",
      "sklearn   0.22.2.post1\n",
      "pandas    0.25.1\n",
      "numpy     1.21.4\n",
      "13:24:16 \n",
      "\n",
      "CPython 3.7.4\n",
      "IPython 7.8.0\n",
      "\n",
      "compiler   : GCC 7.3.0\n",
      "system     : Linux\n",
      "release    : 4.15.0-167-generic\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 8\n",
      "interpreter: 64bit\n"
     ]
    }
   ],
   "source": [
    "%watermark -t -m -v --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load some Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../tests/data/pls_train.csv')\n",
    "raw_X = np.array(df.values[:,3:], dtype=float) # Extract features\n",
    "raw_y = np.array(df['Water'].values, dtype=float) # Take the water content as the target\n",
    "\n",
    "# Randomly delete some entries\n",
    "n_delete = 10\n",
    "\n",
    "np.random.seed(0)\n",
    "a = [np.random.randint(low=0, high=raw_X.shape[0]) \n",
    "     for i in range(n_delete)]\n",
    "b = [np.random.randint(low=0, high=raw_X.shape[1]) \n",
    "     for i in range(n_delete)]\n",
    "\n",
    "missing_X = raw_X.copy()\n",
    "for i,j in zip(a,b):\n",
    "    missing_X[i,j] = np.nan \n",
    "    \n",
    "def compare(raw_X, reconstructed_X):\n",
    "    print('Reconstructed\\tOriginal\\tDifference\\tRelative Err')\n",
    "    for i,j in zip(a,b):\n",
    "        print('%.3e\\t'%reconstructed_X[i,j]\n",
    "              +'%.3e\\t'%raw_X[i,j]\n",
    "              +'%.3e\\t'%(reconstructed_X[i,j]-raw_X[i,j])\n",
    "              +'%.3f'%(np.abs((reconstructed_X[i,j]-raw_X[i,j])/raw_X[i,j]))\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Iterative PCA (Missing X values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Fixed n_components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "If you know the number of components to use you can just perform this directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from chemometrics.preprocessing.missing import PCA_IA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "itim = PCA_IA(n_components=3, \n",
    "              scale_x=True,\n",
    "              missing_values=np.nan, \n",
    "              tol=1.0e-6, \n",
    "              max_iters=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructed\tOriginal\tDifference\tRelative Err\n",
      "5.814e-01\t5.629e-01\t1.848e-02\t0.033\n",
      "-1.458e+00\t-1.457e+00\t-9.806e-04\t0.001\n",
      "6.187e-01\t6.290e-01\t-1.027e-02\t0.016\n",
      "6.521e-01\t6.713e-01\t-1.927e-02\t0.029\n",
      "1.000e+00\t9.980e-01\t2.025e-03\t0.002\n",
      "-1.540e+00\t-1.542e+00\t1.949e-03\t0.001\n",
      "-1.608e+00\t-1.609e+00\t2.426e-04\t0.000\n",
      "1.104e+00\t1.107e+00\t-3.625e-03\t0.003\n",
      "-5.570e-01\t-5.565e-01\t-5.697e-04\t0.001\n",
      "4.703e-01\t4.465e-01\t2.377e-02\t0.053\n"
     ]
    }
   ],
   "source": [
    "reconstructed_X = itim.fit_transform(missing_X)\n",
    "compare(raw_X, reconstructed_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Unknown n_components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Usually, we need to figure out what a good n_components value is. We can use cross-validation for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pipeline = sklearn.pipeline.Pipeline(steps=[\n",
    "    (\"pca_ia\", PCA_IA(\n",
    "        n_components=1, \n",
    "        scale_x=True)\n",
    "    )\n",
    "])\n",
    "\n",
    "# Hyperparameters of pipeline steps are given in standard notation: step__parameter_name\n",
    "param_grid = [{\n",
    "    'pca_ia__n_components': np.arange(1, 10, 2),\n",
    "    'pca_ia__scale_x': [True, False],\n",
    "}]\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    error_score=0,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "_ = gs.fit(missing_X, raw_y.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pca_ia__n_components': 9, 'pca_ia__scale_x': False}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "filler = PCA_IA(\n",
    "        n_components=9, \n",
    "        scale_x=False)\n",
    "reconstructed_X = filler.fit_transform(missing_X, \n",
    "                                       raw_y.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructed\tOriginal\tDifference\tRelative Err\n",
      "5.169e-01\t5.629e-01\t-4.597e-02\t0.082\n",
      "-1.456e+00\t-1.457e+00\t3.158e-04\t0.000\n",
      "6.290e-01\t6.290e-01\t-4.315e-06\t0.000\n",
      "6.116e-01\t6.713e-01\t-5.977e-02\t0.089\n",
      "1.012e+00\t9.980e-01\t1.440e-02\t0.014\n",
      "-1.542e+00\t-1.542e+00\t9.013e-05\t0.000\n",
      "-1.609e+00\t-1.609e+00\t2.404e-05\t0.000\n",
      "1.108e+00\t1.107e+00\t5.621e-05\t0.000\n",
      "-5.563e-01\t-5.565e-01\t1.776e-04\t0.000\n",
      "5.140e-01\t4.465e-01\t6.749e-02\t0.151\n"
     ]
    }
   ],
   "source": [
    "compare(raw_X, reconstructed_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "You can then use this in other pipelines.  You can specify the imputer without any hyperparameters in those cases, for example.\n",
    "Below is an example of how you might do that. Of course, you can also include the imputer's hyperparameters as part of the CV, too."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "pipeline = imblearn.pipeline.Pipeline(steps=[\n",
    "    # Insert other preprocessing steps here...\n",
    "    (\"pca_ia\", PCA_IA(n_components=9, scale_x=False)),\n",
    "    (\"plsda\", PLSDA(n_components=5, \n",
    "                    alpha=0.05,\n",
    "                    scale_x=True, \n",
    "                    not_assigned='UNKNOWN',\n",
    "                    style='soft', \n",
    "                   )\n",
    "    )\n",
    "])\n",
    "\n",
    "# NO HYPERPARAMETERS ASSOCIATED WITH THE IMPUTER\n",
    "param_grid = [{\n",
    "    'plsda__n_components':np.arange(1, 10, 2),\n",
    "    'plsda__alpha': [0.07, 0.05, 0.03, 0.01],\n",
    "}]\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    error_score=0,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "_ = gs.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterative PLS (Missing X and y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixed n_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chemometrics.preprocessing.missing import PLS_IA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "itim = PLS_IA(\n",
    "    n_components=3, \n",
    "    missing_values=np.nan, \n",
    "    scale_x=True,\n",
    "    tol=1.0e-6, \n",
    "    max_iters=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = itim.fit(missing_X, raw_y.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_X = itim.fit_transform(missing_X, raw_y.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructed\tOriginal\tDifference\tRelative Err\n",
      "5.646e-01\t5.629e-01\t1.679e-03\t0.003\n",
      "-1.455e+00\t-1.457e+00\t1.376e-03\t0.001\n",
      "6.299e-01\t6.290e-01\t9.861e-04\t0.002\n",
      "6.705e-01\t6.713e-01\t-7.987e-04\t0.001\n",
      "9.934e-01\t9.980e-01\t-4.562e-03\t0.005\n",
      "-1.541e+00\t-1.542e+00\t1.084e-03\t0.001\n",
      "-1.607e+00\t-1.609e+00\t1.668e-03\t0.001\n",
      "1.106e+00\t1.107e+00\t-1.266e-03\t0.001\n",
      "-5.569e-01\t-5.565e-01\t-4.453e-04\t0.001\n",
      "4.477e-01\t4.465e-01\t1.213e-03\t0.003\n"
     ]
    }
   ],
   "source": [
    "print('Reconstructed\\tOriginal\\tDifference\\tRelative Err')\n",
    "for i,j in zip(a,b):\n",
    "    print('%.3e\\t'%reconstructed_X[i,j]\n",
    "          +'%.3e\\t'%raw_X[i,j]\n",
    "          +'%.3e\\t'%(reconstructed_X[i,j]-raw_X[i,j])\n",
    "          +'%.3f'%(np.abs((reconstructed_X[i,j]-raw_X[i,j])/raw_X[i,j]))\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unknown n_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = sklearn.pipeline.Pipeline(steps=[\n",
    "    (\"pls_ia\", PLS_IA(\n",
    "        n_components=1, \n",
    "        scale_x=True)\n",
    "    )\n",
    "])\n",
    "\n",
    "# Hyperparameters of pipeline steps are given in standard notation: step__parameter_name\n",
    "param_grid = [{\n",
    "    'pls_ia__n_components': np.arange(1, 10, 2),\n",
    "    'pls_ia__scale_x': [True, False],\n",
    "}]\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    n_jobs=-1,\n",
    "    cv=sklearn.model_selection.KFold(\n",
    "        n_splits=3, \n",
    "        shuffle=True, \n",
    "        random_state=0),\n",
    "    error_score=0,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "_ = gs.fit(missing_X, raw_y.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pls_ia__n_components': 9, 'pls_ia__scale_x': False}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
