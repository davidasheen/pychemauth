{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Overview\" data-toc-modified-id=\"Overview-0.1\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;</span>Overview</a></span></li></ul></li><li><span><a href=\"#Load-some-Data\" data-toc-modified-id=\"Load-some-Data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Load some Data</a></span></li><li><span><a href=\"#Iterative-PCA-(Missing-X-values)\" data-toc-modified-id=\"Iterative-PCA-(Missing-X-values)-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Iterative PCA (Missing X values)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Fixed-n_components\" data-toc-modified-id=\"Fixed-n_components-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Fixed n_components</a></span></li><li><span><a href=\"#Unknown-n_components\" data-toc-modified-id=\"Unknown-n_components-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Unknown n_components</a></span></li></ul></li><li><span><a href=\"#Iterative-PLS-(Missing-X-values)\" data-toc-modified-id=\"Iterative-PLS-(Missing-X-values)-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Iterative PLS (Missing X values)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Fixed-n_components\" data-toc-modified-id=\"Fixed-n_components-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Fixed n_components</a></span></li><li><span><a href=\"#Unknown-n_components\" data-toc-modified-id=\"Unknown-n_components-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Unknown n_components</a></span></li></ul></li><li><span><a href=\"#Below-LOD\" data-toc-modified-id=\"Below-LOD-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Below LOD</a></span><ul class=\"toc-item\"><li><span><a href=\"#Missing-values-<-LOD-only\" data-toc-modified-id=\"Missing-values-<-LOD-only-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Missing values &lt; LOD only</a></span></li><li><span><a href=\"#Missing-values-and-<-LOD\" data-toc-modified-id=\"Missing-values-and-<-LOD-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Missing values and &lt; LOD</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "import imblearn\n",
    "import sklearn\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "import chemometrics\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import watermark\n",
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview\n",
    "--------\n",
    "This are some examples ways to impute missing data. scikit-learn has a [library](https://scikit-learn.org/stable/modules/impute.html#univariate-vs-multivariate-imputation) for simple methods which is also very useful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%watermark -t -m -v --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Load some Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../tests/data/pls_train.csv')\n",
    "raw_X = np.array(df.values[:,3:], dtype=float) # Extract features\n",
    "raw_y = np.array(df['Water'].values, dtype=float) # Take the water content as the target\n",
    "\n",
    "# Randomly delete some entries\n",
    "n_delete = 10\n",
    "\n",
    "np.random.seed(0)\n",
    "a = [np.random.randint(low=0, high=raw_X.shape[0]) \n",
    "     for i in range(n_delete)]\n",
    "b = [np.random.randint(low=0, high=raw_X.shape[1]) \n",
    "     for i in range(n_delete)]\n",
    "\n",
    "missing_X = raw_X.copy()\n",
    "for i,j in zip(a,b):\n",
    "    missing_X[i,j] = np.nan \n",
    "    \n",
    "def compare(raw_X, reconstructed_X):\n",
    "    print('Reconstructed\\tOriginal\\tDifference\\tRelative Err')\n",
    "    for i,j in zip(a,b):\n",
    "        print('%.3e\\t'%reconstructed_X[i,j]\n",
    "              +'%.3e\\t'%raw_X[i,j]\n",
    "              +'%.3e\\t'%(reconstructed_X[i,j]-raw_X[i,j])\n",
    "              +'%.3f'%(np.abs((reconstructed_X[i,j]-raw_X[i,j])/raw_X[i,j]))\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Iterative PCA (Missing X values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Fixed n_components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "If you know the number of components to use you can just perform this directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from chemometrics.preprocessing.missing import PCA_IA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "itim = PCA_IA(n_components=3, \n",
    "              scale_x=True,\n",
    "              missing_values=np.nan, \n",
    "              tol=1.0e-6, \n",
    "              max_iters=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "reconstructed_X = itim.fit_transform(missing_X)\n",
    "compare(raw_X, reconstructed_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Unknown n_components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Usually, we need to figure out what a good n_components value is. We can use cross-validation for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pipeline = sklearn.pipeline.Pipeline(steps=[\n",
    "    (\"pca_ia\", PCA_IA(\n",
    "        n_components=1, \n",
    "        scale_x=True)\n",
    "    )\n",
    "])\n",
    "\n",
    "# Hyperparameters of pipeline steps are given in standard notation: step__parameter_name\n",
    "param_grid = [{\n",
    "    'pca_ia__n_components': np.arange(1, 10, 2),\n",
    "    'pca_ia__scale_x': [True, False],\n",
    "}]\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    n_jobs=-1,\n",
    "    cv=sklearn.model_selection.KFold(n_splits=3, shuffle=True, random_state=0),\n",
    "    error_score=0,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "_ = gs.fit(missing_X, raw_y.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "filler = PCA_IA(\n",
    "        n_components=9, \n",
    "        scale_x=False)\n",
    "reconstructed_X = filler.fit_transform(missing_X, \n",
    "                                       raw_y.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "compare(raw_X, reconstructed_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "You can then use this in other pipelines.  You can specify the imputer without any hyperparameters in those cases, for example.\n",
    "Below is an example of how you might do that. Of course, you can also include the imputer's hyperparameters as part of the CV, too."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "pipeline = imblearn.pipeline.Pipeline(steps=[\n",
    "    # Insert other preprocessing steps here...\n",
    "    (\"pca_ia\", PCA_IA(n_components=9, scale_x=False)),\n",
    "    (\"plsda\", PLSDA(n_components=5, \n",
    "                    alpha=0.05,\n",
    "                    scale_x=True, \n",
    "                    not_assigned='UNKNOWN',\n",
    "                    style='soft', \n",
    "                   )\n",
    "    )\n",
    "])\n",
    "\n",
    "# NO HYPERPARAMETERS ASSOCIATED WITH THE IMPUTER\n",
    "param_grid = [{\n",
    "    'plsda__n_components':np.arange(1, 10, 2),\n",
    "    'plsda__alpha': [0.07, 0.05, 0.03, 0.01],\n",
    "}]\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    "    error_score=0,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "_ = gs.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Iterative PLS (Missing X values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Fixed n_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from chemometrics.preprocessing.missing import PLS_IA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "itim = PLS_IA(\n",
    "    n_components=3, \n",
    "    missing_values=np.nan, \n",
    "    scale_x=True,\n",
    "    tol=1.0e-6, \n",
    "    max_iters=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "reconstructed_X = itim.fit_transform(missing_X, raw_y.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "compare(raw_X, reconstructed_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Unknown n_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pipeline = sklearn.pipeline.Pipeline(steps=[\n",
    "    (\"pls_ia\", PLS_IA(\n",
    "        n_components=1, \n",
    "        scale_x=True)\n",
    "    )\n",
    "])\n",
    "\n",
    "# Hyperparameters of pipeline steps are given in standard notation: step__parameter_name\n",
    "param_grid = [{\n",
    "    'pls_ia__n_components': np.arange(1, 10, 2),\n",
    "    'pls_ia__scale_x': [True, False],\n",
    "}]\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=param_grid,\n",
    "    n_jobs=-1,\n",
    "    cv=sklearn.model_selection.KFold(n_splits=3, shuffle=True, random_state=0),\n",
    "    error_score=0,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "_ = gs.fit(missing_X, raw_y.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Below LOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from chemometrics.preprocessing.missing import LOD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Missing values < LOD only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X = np.array(\n",
    "    [\n",
    "        [1.0, 2.0, 3.0, 4.0],\n",
    "        [np.nan, 3.0, 2.0, np.nan],\n",
    "        [5.0, 1.0, np.nan, 5.0],\n",
    "        [2.0, 3.0, 4.0, 5.0]\n",
    "    ]\n",
    ")\n",
    "\n",
    "lod = np.array([0.15, 0.15, 0.25, 0.15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "imputer = LOD(lod, missing_values=np.nan, seed=0)\n",
    "imputer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Missing values and < LOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Now assume -1 indicates < LOD and a corrupted data entry is\n",
    "# indicated by a NaN\n",
    "X = np.array(\n",
    "    [\n",
    "        [1.0, np.nan, 3.0, 4.0],\n",
    "        [-1, 3.0, 2.0, -1],\n",
    "        [5.0, 1.0, -1, 5.0],\n",
    "        [2.0, 3.0, np.nan, 5.0]\n",
    "    ]\n",
    ")\n",
    "\n",
    "lod = np.array([0.15, 0.15, 0.25, 0.15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# If you leave \"-1\" then when doing imputation that will be \n",
    "# considered a \"real\" value which is not what you (probably) want.\n",
    "\n",
    "# Step 1: Remove values encoded by numbers. \n",
    "imputer = LOD(lod, missing_values=-1, seed=0)\n",
    "X_lod = imputer.fit_transform(X)\n",
    "X_lod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Step 2: Remove NaNs by doing imputation\n",
    "itim = PLS_IA(\n",
    "    n_components=2, \n",
    "    missing_values=np.nan, \n",
    "    scale_x=True,\n",
    "    tol=1.0e-6, \n",
    "    max_iters=5000)\n",
    "X_recon = itim.fit_transform(X_lod, np.arange(X.shape[0]).reshape(-1,1))\n",
    "X_recon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Note how some imputed values are now < 0.  This may, or may\n",
    "# not be sensible. If you want, you can re-perform the LOD\n",
    "# check because this will register as < LOD due to the sign.\n",
    "\n",
    "imputer = LOD(lod, missing_values=-1, seed=0)\n",
    "X_lod = imputer.fit_transform(X_recon)\n",
    "X_lod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Lesson: Be careful when combining preprocessing!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
