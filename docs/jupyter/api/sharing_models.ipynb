{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "af0e74e3",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-07-10T12:47:17.460166Z",
          "start_time": "2024-07-10T12:47:17.454006Z"
        },
        "id": "af0e74e3"
      },
      "source": [
        "Saving and Sharing Models\n",
        "==="
      ]
    },
    {
      "cell_type": "markdown",
      "id": "538848a6",
      "metadata": {
        "id": "538848a6"
      },
      "source": [
        "Author: Nathan A. Mahynski\n",
        "\n",
        "Date: 2024/07/10\n",
        "\n",
        "Description: After creating a great model, how can I (easily) save it for future use or share it with someone else?\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mahynski/pychemauth/blob/main/docs/jupyter/api/sharing_models.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b1b9ac2",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-07-10T13:56:44.410829Z",
          "start_time": "2024-07-10T13:56:44.404969Z"
        },
        "id": "1b1b9ac2"
      },
      "outputs": [],
      "source": [
        "if 'google.colab' in str(get_ipython()):\n",
        "    !pip install git+https://github.com/mahynski/pychemauth@main\n",
        "    import os\n",
        "    os.kill(os.getpid(), 9) # Automatically restart the runtime to reload libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b96e772e",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-07-10T13:56:45.289257Z",
          "start_time": "2024-07-10T13:56:44.811184Z"
        },
        "id": "b96e772e"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    import pychemauth\n",
        "except:\n",
        "    raise ImportError(\"pychemauth not installed\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import watermark\n",
        "%load_ext watermark\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "2acd5974",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-07-10T13:56:46.756050Z",
          "start_time": "2024-07-10T13:56:45.291519Z"
        },
        "id": "2acd5974"
      },
      "outputs": [],
      "source": [
        "import imblearn\n",
        "import sklearn\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.datasets import load_iris as load_data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from pychemauth.preprocessing.scaling import CorrectedScaler\n",
        "from pychemauth.classifier.simca import DDSIMCA_Model\n",
        "from pychemauth.utils import HuggingFace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0b576f65",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-07-10T13:56:46.790820Z",
          "start_time": "2024-07-10T13:56:46.758652Z"
        },
        "id": "0b576f65",
        "outputId": "3d2ba911-3258-4f6a-c3c8-cfb542219ec2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python implementation: CPython\n",
            "Python version       : 3.10.12\n",
            "IPython version      : 7.34.0\n",
            "\n",
            "Compiler    : GCC 11.4.0\n",
            "OS          : Linux\n",
            "Release     : 6.1.85+\n",
            "Machine     : x86_64\n",
            "Processor   : x86_64\n",
            "CPU cores   : 2\n",
            "Architecture: 64bit\n",
            "\n",
            "numpy     : 1.24.3\n",
            "watermark : 2.4.3\n",
            "pychemauth: 0.0.0b4\n",
            "matplotlib: 3.7.2\n",
            "sklearn   : 1.3.0\n",
            "imblearn  : 0.11.0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%watermark -t -m -v --iversions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5696470",
      "metadata": {
        "id": "e5696470"
      },
      "source": [
        "Create a Model\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07a1ea54",
      "metadata": {
        "id": "07a1ea54"
      },
      "source": [
        "Let's create a simple model as an example to work with.  in this case, let's build a pipeline which uses a DD-SIMCA model to model a single flower in the iris dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d1701565",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-07-10T13:56:46.818482Z",
          "start_time": "2024-07-10T13:56:46.792329Z"
        },
        "id": "d1701565"
      },
      "outputs": [],
      "source": [
        "X, y = load_data(return_X_y=True, as_frame=True)\n",
        "\n",
        "# Let's turn the indices into names\n",
        "names = dict(zip(np.arange(3), ['setosa', 'versicolor', 'virginica']))\n",
        "y = y.apply(lambda x: names[x])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a419575c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-07-10T13:56:46.883651Z",
          "start_time": "2024-07-10T13:56:46.820682Z"
        },
        "id": "a419575c"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X.values,\n",
        "    y.values, # Let's try to predict the salary based on the other numerical features.\n",
        "    shuffle=True,\n",
        "    random_state=42,\n",
        "    test_size=0.2,\n",
        "    stratify=y # It is usually important to balance the test and train set so they have the same fraction of classes\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "8d6b02d1",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-07-10T13:56:47.556835Z",
          "start_time": "2024-07-10T13:56:47.511069Z"
        },
        "id": "8d6b02d1"
      },
      "outputs": [],
      "source": [
        "# Let's just model a single type of iris for this example\n",
        "chosen_class = 'setosa'\n",
        "\n",
        "X_train_dds = X_train[y_train == chosen_class]\n",
        "y_train_dds = y_train[y_train == chosen_class]\n",
        "\n",
        "X_test_dds = X_test[y_test == chosen_class]\n",
        "y_test_dds = y_test[y_test == chosen_class]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "1c3a78d7",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-07-10T13:56:48.255925Z",
          "start_time": "2024-07-10T13:56:48.211758Z"
        },
        "id": "1c3a78d7"
      },
      "outputs": [],
      "source": [
        "# Now let's build a simple pipeline\n",
        "model = imblearn.pipeline.Pipeline(\n",
        "    steps=[\n",
        "        (\"autoscaler\", CorrectedScaler( # Then, we should center and scale the data\n",
        "            with_mean=True,\n",
        "            with_std=True,\n",
        "            pareto=False\n",
        "            )\n",
        "        ),\n",
        "        (\"my_chosen_model\", DDSIMCA_Model( # Finally, we will pass the cleaned, balanced, and scaled data to the model\n",
        "            n_components=1,\n",
        "            scale_x=True\n",
        "            )\n",
        "        )\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "93df6a06",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-07-10T13:56:48.732785Z",
          "start_time": "2024-07-10T13:56:48.609881Z"
        },
        "id": "93df6a06"
      },
      "outputs": [],
      "source": [
        "_ = model.fit(X_train_dds, y_train_dds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "ae1020da",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-07-10T13:56:49.107578Z",
          "start_time": "2024-07-10T13:56:49.063474Z"
        },
        "id": "ae1020da",
        "outputId": "da5f1ea2-be51-440b-b9ef-bee54af3b887",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True, False,  True,  True,  True, False,  True,  True,\n",
              "        True])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "model.predict(X_test_dds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "83a3e55c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-07-10T13:56:49.692524Z",
          "start_time": "2024-07-10T13:56:49.646151Z"
        },
        "id": "83a3e55c",
        "outputId": "7795ab25-4800-4662-b066-fa3bb54dcc37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'autoscaler': <pychemauth.preprocessing.scaling.CorrectedScaler at 0x7a7bed6be080>,\n",
              " 'my_chosen_model': DDSIMCA_Model(n_components=1)}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "model.named_steps"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab0f55a3",
      "metadata": {
        "id": "ab0f55a3"
      },
      "source": [
        "If we just want to save the model to disk, called \"serialization\", there are a number of ways we can accomplish this.  Perhaps the simplest is just to use [`pickle`](https://docs.python.org/3/library/pickle.html) which is the preferred way to serialize Python objects.  The commands look like this:\n",
        "\n",
        "```python\n",
        "import pickle\n",
        "\n",
        "# To save the model disk, ensure the file is opened with \"w\"rite permissions\n",
        "pickle.dump(model, file=open('my_model.pkl', 'wb'), protocol=4)\n",
        "\n",
        "# To load the model from disk, ensure the file is opened with \"r\"ead permissions\n",
        "stored_model = pickle.load(open('my_model.pkl', 'rb'))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd6fad6d",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-07-10T12:55:58.022823Z",
          "start_time": "2024-07-10T12:55:57.999444Z"
        },
        "id": "cd6fad6d"
      },
      "source": [
        "Hugging Face\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fb19273",
      "metadata": {
        "id": "5fb19273"
      },
      "source": [
        "However, pickling is not most ideal way to store models long term since we can lose track of them and we may forget some of the details of how it works, what it was trained on, etc. if the model is renamed or transferred somewhere else.\n",
        "\n",
        "A better solution is to use a centralized hub service which can store, deploy, track, and document the model.  [Hugging Face](https://huggingface.co/) is one such service."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4538d79",
      "metadata": {
        "id": "f4538d79"
      },
      "source": [
        "<h4>From the Hugging Face Hub <a href=\"https://huggingface.co/docs/hub/index\">documentation</a>:</h4>\n",
        "\n",
        "> \"The Hugging Face Hub is a platform with over 350k models, 75k datasets, and 150k demo apps (Spaces), all open source and publicly available, in an online platform where people can easily collaborate and build ML together. The Hub works as a central place where anyone can explore, experiment, collaborate, and build technology with Machine Learning.\n",
        ">\n",
        "> <h5>What can you find on the Hub?</h5>\n",
        ">\n",
        "> The Hugging Face Hub hosts Git-based repositories, which are version-controlled buckets that can contain all your files. 💾\n",
        ">\n",
        "> On it, you’ll be able to upload and discover…\n",
        ">\n",
        "> * Models, hosting the latest state-of-the-art models for NLP, vision, and audio tasks\n",
        "> * Datasets, featuring a wide variety of data for different domains and modalities..\n",
        "> * Spaces, interactive apps for demonstrating ML models directly in your browser.\n",
        ">\n",
        "> The Hub offers versioning, commit history, diffs, branches, and over a dozen library integrations! You can learn more about the features that all repositories share in the Repositories documentation.\"\n",
        "\n",
        "We strongly encourage you to read the [Model Hub](https://huggingface.co/docs/hub/models-the-hub) and [Model Card](https://huggingface.co/docs/hub/model-cards) documentation.  The former explains how models are stored and accessed from the hub, while the latter explains how models are documented.\n",
        "\n",
        "PyChemAuth provides some simple utilities to get you started, but only a very basic Card is created and you should go to your (newly created) repo and document you model further there."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "9cfe90c1",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-07-10T13:56:53.287843Z",
          "start_time": "2024-07-10T13:56:53.179894Z"
        },
        "id": "9cfe90c1"
      },
      "outputs": [],
      "source": [
        "# Check out the documentation for more information.\n",
        "?HuggingFace.push_to_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "536339bf",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-07-10T13:56:57.197987Z",
          "start_time": "2024-07-10T13:56:57.162364Z"
        },
        "id": "536339bf"
      },
      "outputs": [],
      "source": [
        "# To create repos you will need to specify a token which acts as a password behind the scenes.\n",
        "# To do this, go to hugginface.co and Create a token under Settings > Access Tokens.\n",
        "\n",
        "if 'google.colab' in str(get_ipython()):\n",
        "    # Colab has a nice way to store these \"secrets\" which you can learn about in this YouTube video:\n",
        "    # https://www.youtube.com/watch?v=LPa51KxqUAw\n",
        "    from google.colab import userdata\n",
        "    TOKEN = userdata.get(\n",
        "        'HF_TOKEN' # CHange this to whatever you save you HF token as in the Secrets menu on Colab\n",
        "    )\n",
        "else:\n",
        "    # Otherwise, you can just paste the token here; but be careful not to share this with anyone.\n",
        "    TOKEN = \"hf_*\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "ac59d4bc",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-07-10T13:57:04.418460Z",
          "start_time": "2024-07-10T13:57:02.649208Z"
        },
        "id": "ac59d4bc",
        "outputId": "73be9bbb-bf0a-4371-b988-c22338c42b5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/mahynski/pychemauth-sharing-demo/commit/e2390ed8adc8df53fb6a7d27eda3c090aedc4662', commit_message='Pushing model on 2024-07-10 14:17:24.764004', commit_description='', oid='e2390ed8adc8df53fb6a7d27eda3c090aedc4662', pr_url=None, pr_revision=None, pr_num=None)"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Let's push the model to the hub.\n",
        "# The first time a model is pushed to a repo that doesn't exist, it is created with a basic Card.\n",
        "# In the future, this will only update the repo and should not overwrite anything you put in the Card.\n",
        "HuggingFace.push_to_hub(\n",
        "    model=model,\n",
        "    namespace=\"mahynski\",\n",
        "    repo_name=\"pychemauth-sharing-demo\", # Create a name for this model\n",
        "    private=False, # The default is True, but since this is a demonstration we will set this to public\n",
        "    token=TOKEN\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e85ecabe",
      "metadata": {
        "id": "e85ecabe"
      },
      "source": [
        "Now you can go check the model out at https://huggingface.co/mahynski/pychemauth-sharing-demo.\n",
        "\n",
        "Once the model is there, anyone can download it! This way, you can share models with colleagues easily by just sending them to the correct website. The commands to download a model created by PyChemAuth are given below.\n",
        "\n",
        "**Note: you can also control access to your model by keeping the repo private, or by using [gating](https://huggingface.co/docs/hub/en/models-gated).**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "f90c07ce",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-07-10T13:57:07.812475Z",
          "start_time": "2024-07-10T13:57:07.781617Z"
        },
        "id": "f90c07ce"
      },
      "outputs": [],
      "source": [
        "# Check out the documentation for more information.\n",
        "?HuggingFace.from_pretrained"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "f2c0e9c3",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-07-10T13:57:11.332583Z",
          "start_time": "2024-07-10T13:57:11.182042Z"
        },
        "id": "f2c0e9c3",
        "outputId": "b8f3e210-ae2d-4819-a335-bb21afc66381",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "9462cbb6495d4fd9aefbcac8a820eb60",
            "3e9440e146c24de3a2dbc2585c2bbaae",
            "1e280ad804764478a111feabac36f2f0",
            "54993947ad1c4f99a21694edf1102355",
            "9c6b3cc7097a47ce8859e9121d45cfa9",
            "072416045d654aae9950ab427c6978fb",
            "0204f05f85e342baa1465463493fc7af",
            "7b119652d2324842aeee23d124f06f65",
            "c87dde5bf8ad49789cf2e1a5d6aabaa6",
            "1b6da2efce3d455990ad9961117d584c",
            "97968335eece4ec1b54f14ea0b7eed76"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.pkl:   0%|          | 0.00/3.17k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9462cbb6495d4fd9aefbcac8a820eb60"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "downloaded_model = HuggingFace.from_pretrained(\n",
        "    model_id=\"mahynski/pychemauth-sharing-demo\",\n",
        "    token=None # For public models we don't need a token to access them!\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "23cc7010",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-07-10T13:57:16.969765Z",
          "start_time": "2024-07-10T13:57:16.918462Z"
        },
        "id": "23cc7010",
        "outputId": "e8998eb2-c910-453e-f5cd-50f7851de236",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True, False,  True,  True,  True, False,  True,  True,\n",
              "        True])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "downloaded_model.predict(X_test_dds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "06ce0990",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-07-10T13:57:17.889579Z",
          "start_time": "2024-07-10T13:57:17.840199Z"
        },
        "id": "06ce0990",
        "outputId": "3aa467ab-610b-481d-e029-4f7f9e4f6522",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'autoscaler': <pychemauth.preprocessing.scaling.CorrectedScaler at 0x7a7bed782200>,\n",
              " 'my_chosen_model': DDSIMCA_Model(n_components=1)}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "downloaded_model.named_steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "54dc3764",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-07-10T13:57:18.607473Z",
          "start_time": "2024-07-10T13:57:18.558983Z"
        },
        "id": "54dc3764",
        "outputId": "f033fb27-b396-4efb-ffc1-d85513806459",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "imblearn.pipeline.Pipeline"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>imblearn.pipeline.Pipeline</b><br/>def __init__(steps, *, memory=None, verbose=False)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/imblearn/pipeline.py</a>Pipeline of transforms and resamples with a final estimator.\n",
              "\n",
              "Sequentially apply a list of transforms, sampling, and a final estimator.\n",
              "Intermediate steps of the pipeline must be transformers or resamplers,\n",
              "that is, they must implement fit, transform and sample methods.\n",
              "The samplers are only applied during fit.\n",
              "The final estimator only needs to implement fit.\n",
              "The transformers and samplers in the pipeline can be cached using\n",
              "``memory`` argument.\n",
              "\n",
              "The purpose of the pipeline is to assemble several steps that can be\n",
              "cross-validated together while setting different parameters.\n",
              "For this, it enables setting parameters of the various steps using their\n",
              "names and the parameter name separated by a &#x27;__&#x27;, as in the example below.\n",
              "A step&#x27;s estimator may be replaced entirely by setting the parameter\n",
              "with its name to another estimator, or a transformer removed by setting\n",
              "it to &#x27;passthrough&#x27; or ``None``.\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "steps : list\n",
              "    List of (name, transform) tuples (implementing\n",
              "    fit/transform/fit_resample) that are chained, in the order in which\n",
              "    they are chained, with the last object an estimator.\n",
              "\n",
              "memory : Instance of joblib.Memory or str, default=None\n",
              "    Used to cache the fitted transformers of the pipeline. By default,\n",
              "    no caching is performed. If a string is given, it is the path to\n",
              "    the caching directory. Enabling caching triggers a clone of\n",
              "    the transformers before fitting. Therefore, the transformer\n",
              "    instance given to the pipeline cannot be inspected\n",
              "    directly. Use the attribute ``named_steps`` or ``steps`` to\n",
              "    inspect estimators within the pipeline. Caching the\n",
              "    transformers is advantageous when fitting is time consuming.\n",
              "\n",
              "verbose : bool, default=False\n",
              "    If True, the time elapsed while fitting each step will be printed as it\n",
              "    is completed.\n",
              "\n",
              "Attributes\n",
              "----------\n",
              "named_steps : :class:`~sklearn.utils.Bunch`\n",
              "    Read-only attribute to access any step parameter by user given name.\n",
              "    Keys are step names and values are steps parameters.\n",
              "\n",
              "classes_ : ndarray of shape (n_classes,)\n",
              "    The classes labels.\n",
              "\n",
              "n_features_in_ : int\n",
              "    Number of features seen during first step `fit` method.\n",
              "\n",
              "See Also\n",
              "--------\n",
              "make_pipeline : Helper function to make pipeline.\n",
              "\n",
              "Notes\n",
              "-----\n",
              "See :ref:`sphx_glr_auto_examples_pipeline_plot_pipeline_classification.py`\n",
              "\n",
              ".. warning::\n",
              "   A surprising behaviour of the `imbalanced-learn` pipeline is that it\n",
              "   breaks the `scikit-learn` contract where one expects\n",
              "   `estimmator.fit_transform(X, y)` to be equivalent to\n",
              "   `estimator.fit(X, y).transform(X)`.\n",
              "\n",
              "   The semantic of `fit_resample` is to be applied only during the fit\n",
              "   stage. Therefore, resampling will happen when calling `fit_transform`\n",
              "   while it will only happen on the `fit` stage when calling `fit` and\n",
              "   `transform` separately. Practically, `fit_transform` will lead to a\n",
              "   resampled dataset while `fit` and `transform` will not.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "&gt;&gt;&gt; from collections import Counter\n",
              "&gt;&gt;&gt; from sklearn.datasets import make_classification\n",
              "&gt;&gt;&gt; from sklearn.model_selection import train_test_split as tts\n",
              "&gt;&gt;&gt; from sklearn.decomposition import PCA\n",
              "&gt;&gt;&gt; from sklearn.neighbors import KNeighborsClassifier as KNN\n",
              "&gt;&gt;&gt; from sklearn.metrics import classification_report\n",
              "&gt;&gt;&gt; from imblearn.over_sampling import SMOTE\n",
              "&gt;&gt;&gt; from imblearn.pipeline import Pipeline\n",
              "&gt;&gt;&gt; X, y = make_classification(n_classes=2, class_sep=2,\n",
              "... weights=[0.1, 0.9], n_informative=3, n_redundant=1, flip_y=0,\n",
              "... n_features=20, n_clusters_per_class=1, n_samples=1000, random_state=10)\n",
              "&gt;&gt;&gt; print(f&#x27;Original dataset shape {Counter(y)}&#x27;)\n",
              "Original dataset shape Counter({1: 900, 0: 100})\n",
              "&gt;&gt;&gt; pca = PCA()\n",
              "&gt;&gt;&gt; smt = SMOTE(random_state=42)\n",
              "&gt;&gt;&gt; knn = KNN()\n",
              "&gt;&gt;&gt; pipeline = Pipeline([(&#x27;smt&#x27;, smt), (&#x27;pca&#x27;, pca), (&#x27;knn&#x27;, knn)])\n",
              "&gt;&gt;&gt; X_train, X_test, y_train, y_test = tts(X, y, random_state=42)\n",
              "&gt;&gt;&gt; pipeline.fit(X_train, y_train)\n",
              "Pipeline(...)\n",
              "&gt;&gt;&gt; y_hat = pipeline.predict(X_test)\n",
              "&gt;&gt;&gt; print(classification_report(y_test, y_hat))\n",
              "              precision    recall  f1-score   support\n",
              "&lt;BLANKLINE&gt;\n",
              "           0       0.87      1.00      0.93        26\n",
              "           1       1.00      0.98      0.99       224\n",
              "&lt;BLANKLINE&gt;\n",
              "    accuracy                           0.98       250\n",
              "   macro avg       0.93      0.99      0.96       250\n",
              "weighted avg       0.99      0.98      0.98       250\n",
              "&lt;BLANKLINE&gt;</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 27);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "type(downloaded_model)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9462cbb6495d4fd9aefbcac8a820eb60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3e9440e146c24de3a2dbc2585c2bbaae",
              "IPY_MODEL_1e280ad804764478a111feabac36f2f0",
              "IPY_MODEL_54993947ad1c4f99a21694edf1102355"
            ],
            "layout": "IPY_MODEL_9c6b3cc7097a47ce8859e9121d45cfa9"
          }
        },
        "3e9440e146c24de3a2dbc2585c2bbaae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_072416045d654aae9950ab427c6978fb",
            "placeholder": "​",
            "style": "IPY_MODEL_0204f05f85e342baa1465463493fc7af",
            "value": "model.pkl: 100%"
          }
        },
        "1e280ad804764478a111feabac36f2f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b119652d2324842aeee23d124f06f65",
            "max": 3169,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c87dde5bf8ad49789cf2e1a5d6aabaa6",
            "value": 3169
          }
        },
        "54993947ad1c4f99a21694edf1102355": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b6da2efce3d455990ad9961117d584c",
            "placeholder": "​",
            "style": "IPY_MODEL_97968335eece4ec1b54f14ea0b7eed76",
            "value": " 3.17k/3.17k [00:00&lt;00:00, 155kB/s]"
          }
        },
        "9c6b3cc7097a47ce8859e9121d45cfa9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "072416045d654aae9950ab427c6978fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0204f05f85e342baa1465463493fc7af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b119652d2324842aeee23d124f06f65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c87dde5bf8ad49789cf2e1a5d6aabaa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1b6da2efce3d455990ad9961117d584c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97968335eece4ec1b54f14ea0b7eed76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}